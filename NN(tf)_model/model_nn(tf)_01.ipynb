{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing, feature_selection, metrics, model_selection, decomposition\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import time\n",
    "import random\n",
    "from itertools import product\n",
    "import pickle\n",
    "\n",
    "import psutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = Path(r\"..\\\\..\\\\Data\\\\Input\")\n",
    "\n",
    "feature_directory = Path(r\"..\\\\..\\\\Data\\\\Feature\")\n",
    "\n",
    "model_name = \"model_nn(tf)_01\"\n",
    "model_directory = Path()/model_name\n",
    "model_directory.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(dic, save_path):\n",
    "    with open(save_path, 'wb') as f:\n",
    "    # with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(dic, f)\n",
    "\n",
    "def load_pickle(load_path):\n",
    "    with open(load_path, 'rb') as f:\n",
    "    # with gzip.open(load_path, 'rb') as f:\n",
    "        message_dict = pickle.load(f)\n",
    "    return message_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_parquet(input_directory/'train_low_mem.parquet', engine='pyarrow').set_index(['time_id','investment_id'])\n",
    "# df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data.drop('row_id', axis=1)\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data_norm = df_data.copy()\n",
    "\n",
    "# for i in tqdm(range(300)):\n",
    "#     feature = f'f_{i}'\n",
    "\n",
    "#     df_data_norm[feature] = df_data[feature].groupby(level='time_id').apply(\n",
    "#         lambda x: pd.DataFrame(preprocessing.RobustScaler(quantile_range=(1., 99.), with_scaling=True, with_centering=True).fit_transform(x.values.reshape(-1, 1)), index=x.index, columns=[f'f_{i}']))\n",
    "\n",
    "\n",
    "# df_data_norm.to_parquet(input_directory/'train_norm2.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_norm = pd.read_parquet(input_directory/'train_norm2.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'histgram of normalized feature'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(18, 4))\n",
    "# ax = plt.subplot(121)\n",
    "# df_data['f_1'].plot(kind='hist', bins=200, ax=ax, title=\"histgram of raw feature\")\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "df_data_norm['f_2'].plot(kind='hist', bins=200, ax=ax, title=\"histgram of normalized feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Feature & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_id  investment_id\n",
       "0        1               -0.300875\n",
       "         2               -0.231040\n",
       "         6                0.568807\n",
       "         7               -1.064780\n",
       "         8               -0.531940\n",
       "                            ...   \n",
       "1219     3768             0.033600\n",
       "         3769            -0.223264\n",
       "         3770            -0.559415\n",
       "         3772             0.009599\n",
       "         3773             1.212112\n",
       "Name: target, Length: 3141410, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = df_data_norm.pop('target')\n",
    "feature = df_data_norm\n",
    "# target = target.reset_index(drop=True)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.133483</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.232203</td>\n",
       "      <td>0.027035</td>\n",
       "      <td>-0.084325</td>\n",
       "      <td>0.295687</td>\n",
       "      <td>0.323107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.565489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102298</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049540</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.239130</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>0.119334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108289</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>0.160293</td>\n",
       "      <td>-0.011403</td>\n",
       "      <td>0.029314</td>\n",
       "      <td>0.390865</td>\n",
       "      <td>0.426703</td>\n",
       "      <td>0.295676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.097370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025318</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.209301</td>\n",
       "      <td>-0.285416</td>\n",
       "      <td>-0.006368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022050</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.119521</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>0.091237</td>\n",
       "      <td>-0.229989</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>-0.347619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.298825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.059196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.127263</td>\n",
       "      <td>-0.063854</td>\n",
       "      <td>0.104602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.544325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424744</td>\n",
       "      <td>-0.008875</td>\n",
       "      <td>-0.063067</td>\n",
       "      <td>-0.171823</td>\n",
       "      <td>0.242565</td>\n",
       "      <td>0.057936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.080431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.171502</td>\n",
       "      <td>0.262178</td>\n",
       "      <td>-0.087566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.114755</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>0.531115</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.070495</td>\n",
       "      <td>-0.155961</td>\n",
       "      <td>-0.246051</td>\n",
       "      <td>0.323107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.098786</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226062</td>\n",
       "      <td>0.312121</td>\n",
       "      <td>-0.080823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1219</th>\n",
       "      <th>3768</th>\n",
       "      <td>-0.047359</td>\n",
       "      <td>-0.148677</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-0.017038</td>\n",
       "      <td>-0.092924</td>\n",
       "      <td>0.378928</td>\n",
       "      <td>0.318737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.387626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080894</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.105754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063816</td>\n",
       "      <td>-0.096651</td>\n",
       "      <td>-0.068704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>-0.374504</td>\n",
       "      <td>-0.029735</td>\n",
       "      <td>-0.035861</td>\n",
       "      <td>-0.006363</td>\n",
       "      <td>-0.048209</td>\n",
       "      <td>-0.029534</td>\n",
       "      <td>-0.402315</td>\n",
       "      <td>0.339488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.107742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.107359</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>-0.294157</td>\n",
       "      <td>-0.070620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>0.154132</td>\n",
       "      <td>-0.237883</td>\n",
       "      <td>0.186720</td>\n",
       "      <td>-0.009407</td>\n",
       "      <td>-0.012827</td>\n",
       "      <td>0.291013</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170720</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.022208</td>\n",
       "      <td>-0.489768</td>\n",
       "      <td>-0.003278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>-0.652056</td>\n",
       "      <td>0.089206</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.435851</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>-0.146850</td>\n",
       "      <td>0.091365</td>\n",
       "      <td>-0.286822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.302704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170720</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.053337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018566</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.147317</td>\n",
       "      <td>0.130867</td>\n",
       "      <td>-0.020435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>-0.088998</td>\n",
       "      <td>0.059471</td>\n",
       "      <td>-0.123831</td>\n",
       "      <td>0.139659</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>0.257889</td>\n",
       "      <td>-0.286822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.524376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.069543</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>0.170569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141410 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            f_0       f_1       f_2       f_3       f_4  \\\n",
       "time_id investment_id                                                     \n",
       "0       1              0.133483  0.025641 -0.107040  0.232203  0.027035   \n",
       "        2              0.108289 -0.102564  0.160293 -0.011403  0.029314   \n",
       "        6              0.022050  0.128205  0.119521 -0.009270  0.091237   \n",
       "        7             -0.544325  0.000000  0.424744 -0.008875 -0.063067   \n",
       "        8              0.114755 -0.051282  0.531115 -0.003263 -0.070495   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "1219    3768          -0.047359 -0.148677 -0.083344 -0.002532 -0.017038   \n",
       "        3769          -0.374504 -0.029735 -0.035861 -0.006363 -0.048209   \n",
       "        3770           0.154132 -0.237883  0.186720 -0.009407 -0.012827   \n",
       "        3772          -0.652056  0.089206  0.000941  0.435851 -0.010454   \n",
       "        3773          -0.088998  0.059471 -0.123831  0.139659  0.122948   \n",
       "\n",
       "                            f_5       f_6       f_7  f_8       f_9  ...  \\\n",
       "time_id investment_id                                               ...   \n",
       "0       1             -0.084325  0.295687  0.323107  0.0 -0.565489  ...   \n",
       "        2              0.390865  0.426703  0.295676  0.0 -0.076149  ...   \n",
       "        6             -0.229989  0.299662 -0.347619  0.0 -0.298825  ...   \n",
       "        7             -0.171823  0.242565  0.057936  0.0 -0.337304  ...   \n",
       "        8             -0.155961 -0.246051  0.323107  0.0 -0.017943  ...   \n",
       "...                         ...       ...       ...  ...       ...  ...   \n",
       "1219    3768          -0.092924  0.378928  0.318737  0.0 -0.387626  ...   \n",
       "        3769          -0.029534 -0.402315  0.339488  0.0 -0.329040  ...   \n",
       "        3770           0.291013  0.030878  0.000000  0.0  0.253357  ...   \n",
       "        3772          -0.146850  0.091365 -0.286822  0.0 -0.302704  ...   \n",
       "        3773           0.096628  0.257889 -0.286822  0.0 -0.524376  ...   \n",
       "\n",
       "                          f_290  f_291     f_292  f_293  f_294     f_295  \\\n",
       "time_id investment_id                                                      \n",
       "0       1              0.102298   -1.0  0.097949    0.0    0.0  0.049540   \n",
       "        2             -0.003282    0.0 -0.097370    0.0    0.0 -0.025318   \n",
       "        6              0.000000    0.0 -0.059196   -1.0   -1.0  0.016613   \n",
       "        7              0.105580    0.0  0.000476   -1.0    0.0 -0.080431   \n",
       "        8             -0.006564    0.0 -0.098786   -1.0    0.0 -0.075289   \n",
       "...                         ...    ...       ...    ...    ...       ...   \n",
       "1219    3768          -0.080894   -1.0 -0.105754    0.0    0.0 -0.031788   \n",
       "        3769           0.008933   -1.0 -0.107742    0.0    0.0 -0.107359   \n",
       "        3770          -0.170720   -1.0  0.191191   -1.0    0.0 -0.015572   \n",
       "        3772          -0.170720   -1.0  0.053337   -1.0    0.0 -0.018566   \n",
       "        3773          -0.086849    0.0  0.682466    0.0    0.0  0.032652   \n",
       "\n",
       "                       f_296     f_297     f_298     f_299  \n",
       "time_id investment_id                                       \n",
       "0       1               -0.5 -0.239130 -0.108588  0.119334  \n",
       "        2               -0.5 -0.209301 -0.285416 -0.006368  \n",
       "        6               -0.5 -0.127263 -0.063854  0.104602  \n",
       "        7                0.0 -0.171502  0.262178 -0.087566  \n",
       "        8                0.0  0.226062  0.312121 -0.080823  \n",
       "...                      ...       ...       ...       ...  \n",
       "1219    3768             0.0 -0.063816 -0.096651 -0.068704  \n",
       "        3769            -0.5  0.039689 -0.294157 -0.070620  \n",
       "        3770             0.5  0.022208 -0.489768 -0.003278  \n",
       "        3772            -0.5 -0.147317  0.130867 -0.020435  \n",
       "        3773             0.5 -0.069543  0.148146  0.170569  \n",
       "\n",
       "[3141410 rows x 300 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature = feature.reset_index(drop=True)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_id = df_data_norm.index.get_level_values(\n",
    "    'investment_id').to_series().reset_index(drop=True)\n",
    "\n",
    "\n",
    "investment_ids = list(investment_id.unique())\n",
    "\n",
    "investment_id_size = len(investment_ids) + 1\n",
    "investment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\n",
    "with tf.device(\"cpu\"):\n",
    "    investment_id_lookup_layer.adapt(investment_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_start: 0, train_end: 1018, test_start: 1019, test_end: 1219\n"
     ]
    }
   ],
   "source": [
    "train_test_ratio = 5\n",
    "\n",
    "uniquedate = target.index.get_level_values(level='time_id').unique().tolist()\n",
    "train_start = 0\n",
    "train_end = uniquedate[int(\n",
    "    len(uniquedate)*train_test_ratio/(train_test_ratio+1))]\n",
    "test_start = uniquedate[int(\n",
    "    len(uniquedate)*train_test_ratio/(train_test_ratio+1))+1]\n",
    "test_end = 1219\n",
    "\n",
    "\n",
    "# dates of train, dates of test\n",
    "print(\n",
    "    f'train_start: {train_start}, train_end: {train_end}, test_start: {test_start}, test_end: {test_end}')\n",
    "\n",
    "feature_train = feature.loc[idx[train_start:train_end, :], :]\n",
    "feature_test = feature.loc[idx[test_start:test_end, :], :]\n",
    "\n",
    "target_train = target.loc[idx[train_start:train_end, :]]\n",
    "target_test = target.loc[idx[test_start:test_end, :]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2490893, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_train_valid_data(X, y, train_idx, test_idx):\n",
    "    # x_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    # x_val, y_val = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    # scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    # x_train = scaler.fit_transform(x_train)\n",
    "    # x_val = scaler.transform(x_val)\n",
    "    return (X.iloc[train_idx, :], y.iloc[train_idx], \n",
    "            X.iloc[test_idx, :], y.iloc[test_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_corr(y_actual, y_pred):\n",
    "    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n",
    "    \n",
    "    y_actual = (y_actual - tf.reduce_mean(y_actual))/tf.sqrt(tf.reduce_sum(tf.square(y_actual - tf.reduce_mean(y_actual))))\n",
    "    y_pred = (y_pred - tf.reduce_mean(y_pred))/tf.sqrt(tf.reduce_sum(tf.square(y_pred - tf.reduce_mean(y_pred))))\n",
    "\n",
    "    return tf.reduce_sum(y_actual*y_pred)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    return np.corrcoef(y_true, y_pred)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " integer_lookup (IntegerLookup)  (None, 1)           0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 64)        229120      ['integer_lookup[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 64)           0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           4160        ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          77056       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          32896       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           4160        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           8256        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           2080        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           528         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            17          ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 370,689\n",
      "Trainable params: 370,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    investment_id_inputs = tf.keras.layers.Input(shape=(1, ))\n",
    "    features_inputs = tf.keras.Input(shape=(300, ))\n",
    "\n",
    "    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n",
    "    investment_id_x = layers.Embedding(\n",
    "        investment_id_size, 64, input_length=1)(investment_id_x)\n",
    "    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "\n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dense(128, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dense(64, activation='swish')(feature_x)\n",
    "\n",
    "    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n",
    "    x = layers.Dense(64, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(16, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[investment_id_inputs, features_inputs], outputs=[output])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.001),\n",
    "                  loss='huber', metrics=['mse', custom_corr])\n",
    "    return model\n",
    "\n",
    "get_model().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 4\n",
    "\n",
    "n_splits = 2\n",
    "\n",
    "cv = model_selection.KFold(\n",
    "    n_splits=n_splits, random_state=2021, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, memory: 93.90%\n",
      "Epoch 1/4\n",
      "9731/9731 [==============================] - 29s 3ms/step - loss: 1.6331 - mse: 1107372.0000 - custom_corr: 0.1358 - val_loss: 0.5899 - val_mse: 12340.0566 - val_custom_corr: 0.1491\n",
      "Epoch 2/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 0.3865 - mse: 769.3234 - custom_corr: 0.1582 - val_loss: 0.3216 - val_mse: 0.8538 - val_custom_corr: 0.1476\n",
      "Epoch 3/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 0.3303 - mse: 187.1134 - custom_corr: 0.1722 - val_loss: 0.3105 - val_mse: 0.8377 - val_custom_corr: 0.1606\n",
      "Epoch 4/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 0.3068 - mse: 0.8279 - custom_corr: 0.1866 - val_loss: 0.3073 - val_mse: 0.8367 - val_custom_corr: 0.1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:51, 111.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, memory: 62.40%\n",
      "Epoch 1/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 1.4015 - mse: 59114.8828 - custom_corr: 0.1221 - val_loss: 0.8154 - val_mse: 3537.5808 - val_custom_corr: 0.1382\n",
      "Epoch 2/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 0.4278 - mse: 46.0289 - custom_corr: 0.1553 - val_loss: 0.3153 - val_mse: 0.8445 - val_custom_corr: 0.1544\n",
      "Epoch 3/4\n",
      "9731/9731 [==============================] - 24s 2ms/step - loss: 0.3238 - mse: 153.2866 - custom_corr: 0.1702 - val_loss: 0.3085 - val_mse: 0.8358 - val_custom_corr: 0.1601\n",
      "Epoch 4/4\n",
      "9731/9731 [==============================] - 25s 3ms/step - loss: 0.3070 - mse: 0.9881 - custom_corr: 0.1837 - val_loss: 0.3080 - val_mse: 0.8328 - val_custom_corr: 0.1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:32, 106.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, valid_idx) in tqdm(enumerate(cv.split(X=feature_train))):\n",
    "    print(f'fold: {fold}, memory: {psutil.virtual_memory().percent/100:.2%}')\n",
    "\n",
    "    model = get_model()\n",
    "    \n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = get_train_valid_data(\n",
    "        feature_train, target_train, train_idx, valid_idx)\n",
    "\n",
    "    id_train = X_train.index.get_level_values(\n",
    "        'investment_id').to_series().reset_index(drop=True)\n",
    "    id_valid = X_valid.index.get_level_values(\n",
    "        'investment_id').to_series().reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        model_directory/f\"model_{fold}.tf\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, save_weights_only=True)\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "    model.fit((id_train, X_train), y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=((id_valid, X_valid), y_valid),\n",
    "                        epochs=epochs,\n",
    "                        #   verbose=0,\n",
    "                        shuffle=True,\n",
    "                        callbacks=[checkpoint_cb, early_stop_cb]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_list = []\n",
    "\n",
    "\n",
    "for fold in range(n_splits):\n",
    "    model = get_model()\n",
    "    model.load_weights(model_directory/f\"model_{fold}.tf\")\n",
    "    best_models_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test | mse_test: 0.81446 | corr_test: 0.13062\n"
     ]
    }
   ],
   "source": [
    "y_test_fit_list = []\n",
    "for (i, model) in enumerate(best_models_list):\n",
    "    id_test = feature_test.index.get_level_values(\n",
    "        'investment_id').to_series().reset_index(drop=True)\n",
    "    y_test_fit = model.predict((id_test, feature_test))\n",
    "    y_test_fit_list.append(y_test_fit)\n",
    "\n",
    "y_test_fit = pd.DataFrame(index=feature_test.index)\n",
    "y_test_fit['actual'] = target_test\n",
    "y_test_fit['predict'] = np.mean(y_test_fit_list, axis=0).squeeze()\n",
    "\n",
    "corr_train = corr(y_test_fit['actual'], y_test_fit['predict'])\n",
    "corr_test = corr(y_test_fit['actual'], y_test_fit['predict'])\n",
    "mse_train = metrics.mean_squared_error(\n",
    "    y_test_fit['actual'], y_test_fit['predict'])\n",
    "mse_test = metrics.mean_squared_error(\n",
    "    y_test_fit['actual'], y_test_fit['predict'])\n",
    "print(\n",
    "    f' test | mse_test: {mse_train:.5f} | corr_test: {corr_train:0.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(best_models_list, model_directory/'best_model_list')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e2c26d81da9559881f4d926ec79778e2b8c97ac068d329245981963e3d233b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
